{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dog Breed Analysis\n",
    "<div>\n",
    "<img src=\"puppytraining.jpeg\" width=\"400\" height = \"300\"/>\n",
    "</div>\n",
    "\n",
    "1. Data cleaning\n",
    "2. EDA\n",
    "3. Recommendation System\n",
    "    - Euclidian distance\n",
    "    - PCA with K mean clustering\n",
    "    - matrix factorization\n",
    "4. Compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "from IPython.display import Image, display\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'dog_data.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/ly/yp1zttk15gsc1kxg7rl2plgr0000gn/T/ipykernel_56330/906581386.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"dog_data.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1038\u001b[0m             )\n\u001b[1;32m   1039\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \"\"\"\n\u001b[0;32m--> 222\u001b[0;31m         self.handles = get_handle(\n\u001b[0m\u001b[1;32m    223\u001b[0m             \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    700\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    703\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'dog_data.csv'"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"dog_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(1)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Data Cleaning\n",
    "#### cleaning height, weight, life expectancy and poplarity ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's do data cleaning for height, weight, life expectancy, popularity ranking\n",
    "def is_number(string):\n",
    "    try:\n",
    "        float(string)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "def hwl_clean(height): # height weight life clean\n",
    "    height = str(height)\n",
    "    height_list = height.split('-')\n",
    "    result = []\n",
    "    for word in height_list:\n",
    "        result = result + word.split(\" \")\n",
    "    avg_val = 0\n",
    "    count = 0\n",
    "    for i in result:\n",
    "        if is_number(i):\n",
    "            count = count +1\n",
    "            avg_val = avg_val + float(i)\n",
    "    if count != 0:\n",
    "        avg_val = avg_val / count\n",
    "        return avg_val\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "df['height_c'] = df['height'].apply(hwl_clean)\n",
    "df['weight_c'] = df['weight'].apply(hwl_clean)\n",
    "df['life_c'] = df['life_expectancy'].apply(hwl_clean)\n",
    "\n",
    "# replace the outlier with the mean value\n",
    "mean_val = (df[\"life_c\"].sum() - df[\"life_c\"].max()) / 275\n",
    "df[\"life_c\"].replace(df[\"life_c\"].max(), mean_val, inplace= True)\n",
    "\n",
    "df.drop(['height','weight','life_expectancy'], axis = 1,inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['height_c','weight_c','life_c']].isnull().sum()\n",
    "# we are missing 10,20,2 values from height, weight and life respectively"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### cleaning popularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's do data cleaning for popularity\n",
    "def popular_clean(pop):\n",
    "    if type(pop) == float:\n",
    "        return np.nan\n",
    "    else:\n",
    "        rank_list = pop.split(\" of \")\n",
    "        measure = int(rank_list[0]) / int(rank_list[1])\n",
    "        return 1 - measure\n",
    "\n",
    "df['popularity_rank_c']= df['popularity_rank'].apply(popular_clean)\n",
    "df.drop('popularity_rank', axis = 1, inplace = True)\n",
    "df['Coat Length'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### cleaning coat length. minize the categories to long, medium and short then change it to numeric value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coat Length has to be cleaned\n",
    "df[df['Coat Length'] == 'Short-Long']\n",
    "def coatLen_clean(coat):\n",
    "    if type(coat) != float:\n",
    "        if \"Long\" in coat:\n",
    "            return 3\n",
    "        elif \"Medium\" in coat:\n",
    "            return 2\n",
    "        else:\n",
    "            return 1\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "df[\"Coat_Length_c\"] = df[\"Coat Length\"].apply(coatLen_clean)\n",
    "df.drop(\"Coat Length\", axis = 1, inplace= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning coat type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coat_dict = {}\n",
    "for i in df[\"Coat Type\"]:\n",
    "    if type(i) != float:\n",
    "        coat_list = i.split('-')\n",
    "        for coat in coat_list:\n",
    "            if coat not in coat_dict:\n",
    "                coat_dict[coat] = 1\n",
    "            else:\n",
    "                coat_dict[coat] = coat_dict[coat] + 1\n",
    "\n",
    "new_dict = dict(sorted(coat_dict.items(), key=lambda item: item[1], reverse= True))\n",
    "new_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coat_clean(coat):\n",
    "    if type(coat) != float:\n",
    "        if 'Double' in coat:\n",
    "            return 'Double'\n",
    "        elif 'Smooth' in coat:\n",
    "            return 'Smooth'\n",
    "        elif 'Wiry' in coat:\n",
    "            return 'Wiry'\n",
    "        elif 'Silky' in coat:\n",
    "            return 'Silky'\n",
    "        elif 'Curly' in coat:\n",
    "            return 'Curly'\n",
    "        elif 'Rough' in coat:\n",
    "            return 'Rough'\n",
    "        elif 'Corded' in coat:\n",
    "            return 'Corded'\n",
    "        elif 'Hairless' in coat:\n",
    "            return 'Hairless'\n",
    "    else:\n",
    "        return np.nan\n",
    "df['coat_c'] = df['Coat Type'].apply(coat_clean)\n",
    "df.drop(\"Coat Type\", axis = 1, inplace = True)\n",
    "df.drop(\"marking\", axis = 1, inplace = True)\n",
    "df.drop(\"color\", axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reorganize in the way that I like to see\n",
    "\n",
    "df = df[['dog','popularity_rank_c','height_c', 'weight_c', 'life_c','Coat_Length_c', 'coat_c','Affectionate With Family',\n",
    "       'Good With Young Children', 'Good With Other Dogs', 'Shedding Level',\n",
    "       'Coat Grooming Frequency', 'Drooling Level', 'Openness To Strangers',\n",
    "       'Playfulness Level', 'Watchdog/Protective Nature', 'Adaptability Level',\n",
    "       'Trainability Level', 'Energy Level', 'Barking Level',\n",
    "       'Mental Stimulation Needs', 'breed_info', 'health', 'grooming',\n",
    "       'excercise', 'training', 'nutrition']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. EDA\n",
    "#### 1) histogram for qunatative data\n",
    "#### 2) histogram for categorical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.hist(bins = 20, figsize = (15,10))\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from the histogram above, we can see that there are outliers with value 0. Let's replace 0 with mean value\n",
    "\n",
    "def replace_w_mean(df,col,val2replace):\n",
    "    count_of_val = df[df[col] == val2replace][col].count()\n",
    "    mean_val = (df[col].sum() - val2replace * count_of_val) / (df[col].count() - count_of_val)\n",
    "    df[col].replace(val2replace,mean_val,inplace = True)\n",
    "\n",
    "numeric_columns = list(df.select_dtypes(include=[np.number]).columns)\n",
    "for col in numeric_columns:\n",
    "    print(col)\n",
    "    replace_w_mean(df,col,0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numeric_data = df.select_dtypes(include=[np.number])\n",
    "# categorical_data = df.select_dtypes(exclude=[np.number])\n",
    "# list(categorical_data.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Recommendation System\n",
    "#### Let me start with the most obivous way. \"Euclidean distance Recommendation system\"\n",
    "#### there are two ways to use this recommendation system\n",
    "##### 1) choose the dog you like -> recommend the five other dogs that is similar with the dog you chose\n",
    "##### 2) answer question about the traits -> recommend the five other dogs that is similar with the dog you chose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's choose what columns to include for the eudlidean distance recommendation system\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's choose \n",
    "euclidean_cols = ['height_c', 'weight_c', 'life_c',\n",
    "       'Coat_Length_c', 'Affectionate With Family',\n",
    "       'Good With Young Children', 'Good With Other Dogs', 'Shedding Level',\n",
    "       'Coat Grooming Frequency', 'Drooling Level', 'Openness To Strangers',\n",
    "       'Playfulness Level', 'Watchdog/Protective Nature', 'Adaptability Level',\n",
    "       'Trainability Level', 'Energy Level', 'Barking Level',\n",
    "       'Mental Stimulation Needs']\n",
    "df_euclidean = df[euclidean_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's normalize the dataset\n",
    "df_euclidean.fillna(df_euclidean.mean(), inplace = True)\n",
    "normalized_df_euclidean=(df_euclidean-df_euclidean.min())/(df_euclidean.max()-df_euclidean.min())\n",
    "normalized_df_euclidean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_idx(df,dog_name):\n",
    "    return df[df['dog']== dog_name].index.to_list()[0]\n",
    "\n",
    "def get_names(df,dog_name):\n",
    "    dist_list = []\n",
    "    for i in range(df.shape[0]):\n",
    "        dist_list.append(np.linalg.norm(normalized_df_euclidean.iloc[get_idx(df,dog_name)]-normalized_df_euclidean.iloc[i]))\n",
    "    idx_list = sorted(range(len(dist_list)), key=lambda i: dist_list[i], reverse=False)[:6]\n",
    "    return df['dog'][idx_list], 1- (sorted(dist_list)[0:6] / sorted(dist_list)[-1])\n",
    "\n",
    "def euclidean_by_name(df, dog_name):\n",
    "    name_list, dis = get_names(df,dog_name)\n",
    "    for name,d in zip(name_list,dis):\n",
    "        print(name)\n",
    "        print(format(d,'.2%'), \"simliar to\", dog_name)\n",
    "        display(Image(filename=f'img/{name}.jpg'))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "euclidean_by_name(df,\"Australian-Cattle-Dog\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_euclidean['height_c'].min(),df_euclidean['height_c'].max(),df_euclidean['weight_c'].min(),df_euclidean['weight_c'].max(),df_euclidean['life_c'].min(),df_euclidean['life_c'].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recommendation based on the answering the questions\n",
    "questions = ['height_c', 'weight_c', 'life_c',\n",
    "       'Coat_Length_c', 'Affectionate With Family',\n",
    "       'Good With Young Children', 'Good With Other Dogs', 'Shedding Level',\n",
    "       'Coat Grooming Frequency', 'Drooling Level', 'Openness To Strangers',\n",
    "       'Playfulness Level', 'Watchdog/Protective Nature', 'Adaptability Level',\n",
    "       'Trainability Level', 'Energy Level', 'Barking Level',\n",
    "       'Mental Stimulation Needs']\n",
    "height = float(input(\"how do you want the height to be(in inches) 6.5 -> 32.0 : \"))\n",
    "height = (height - 6.5) / 32.0\n",
    "weight = float(input(\"how do you want the weight to be(in pounds) 5.0 -> 195: \"))\n",
    "weight = (weight - 5) / 195\n",
    "life = float(input(\"how long do you want them to live(in years) : \"))\n",
    "life = (life - 6.5)/ 18\n",
    "coat = float(input(\"short, medium, long 1/2/3: \")) \n",
    "coat = (coat - 1)/3\n",
    "affection = float(input(\"ind or lovey-dovey 1->5: \"))\n",
    "affection = (affection - 1) / 5\n",
    "goodwkid = float(input(\"good with kid, not recommended to good 1->5: \"))\n",
    "goodwkid = (goodwkid - 1) / 5\n",
    "goodwdog = float(input(\"good with other dog, not recommended to good 1->5: \"))\n",
    "goodwdog = (goodwdog - 1) / 5\n",
    "shedding = float(input(\"no shedding to a lot of hair 1->5: \"))\n",
    "shedding = (shedding - 1) / 5\n",
    "grooming = float(input(\"grooming, monthly to daily 1->5: \"))\n",
    "grooming = (grooming - 1) / 5\n",
    "drooling = float(input(\"no drooling to have towel 1 -> 5: \"))\n",
    "drooling = (drooling - 1) / 5\n",
    "opentostranger = float(input(\"reserved to open to every one 1->5: \"))\n",
    "opentostranger = (opentostranger - 1) / 5\n",
    "playfulness = float(input(\"only when you want to play to Non-stop 1 ->5 :\"))\n",
    "playfulness = (playfulness - 1) / 5\n",
    "watchdog = float(input(\"peaceful to watchdog 1 ->5: \"))\n",
    "watchdog = (watchdog - 1) / 5\n",
    "adaptibility = float(input(\"routine needed to highly adaptable 1 ->5: \"))\n",
    "adaptibility = (adaptibility - 1) / 5\n",
    "trainability = float(input(\"easy to train to difficult to train 1 -> 5: \"))\n",
    "trainability = (trainability - 1) / 5\n",
    "energy = float(input(\"easy going to need to run every single second 1->5 :\"))\n",
    "energy = (energy - 1) / 5\n",
    "barking = float(input(\"queit dog to loud dog: \"))\n",
    "barking = (barking - 1) / 5\n",
    "mental = float(input(\"easy going to need a job asap: 1-> 5: \"))\n",
    "mental = (mental - 1) / 5\n",
    "profile = [height, weight,life, coat, affection, goodwkid,goodwdog,shedding,grooming,drooling,opentostranger,playfulness,watchdog,adaptibility,trainability,energy,barking,mental]\n",
    "\n",
    "# get the input and standardize them based on the previously defined largest and smallest value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_names(df,profile):\n",
    "    dist_list = []\n",
    "    for i in range(df.shape[0]):\n",
    "        dist_list.append(np.linalg.norm(profile-normalized_df_euclidean.iloc[i]))\n",
    "    idx_list = sorted(range(len(dist_list)), key=lambda i: dist_list[i], reverse=False)[:5]\n",
    "    return df['dog'][idx_list], 1- (sorted(dist_list)[0:5] / sorted(dist_list)[-1])\n",
    "\n",
    "def euclidean_by_profile(df, profile):\n",
    "    name_list, dis = get_names(df,profile)\n",
    "    for name,d in zip(name_list,dis):\n",
    "        print(name)\n",
    "        print(format(d,'.2%'), \"matching with profile\")\n",
    "        display(Image(filename=f'img/{name}.jpg'))\n",
    "\n",
    "euclidean_by_profile(df,profile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pca = df.drop(['breed_info', 'health', 'grooming', 'excercise', 'training', 'nutrition'], axis =1) # drop columns with text\n",
    "\n",
    "print(df_pca.shape)\n",
    "df_pca.dropna(inplace = True)\n",
    "print(df_pca.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(df_pca.drop(['dog','coat_c'], axis = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "kmeans = KMeans(\n",
    "    init=\"random\",\n",
    "     n_clusters=3,\n",
    "    n_init=10,\n",
    "    max_iter=300,\n",
    "    random_state=42 )\n",
    "kmeans.fit(scaled_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "components = pca.fit_transform(scaled_data)\n",
    "print(pca.explained_variance_ratio_)\n",
    "plt.scatter(components[:,0],components[:,1], c= kmeans.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = components\n",
    "fig = px.scatter(df1, x=df1[:,0], y=df1[:,1], color = kmeans.labels_, hover_name = df_pca.dog)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "29f9ce33f6c884e3855952bfd7c8e1ec7ab3eef33d7abd85991a8524700c864f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
