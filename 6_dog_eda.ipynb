{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "import seaborn as sns\n",
    "import matplotlib.dates as mdates\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Machine Learning / Time Series\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "from factor_analyzer import FactorAnalyzer\n",
    "\n",
    "# Snowflake & ETC\n",
    "import datetime\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"dog_data_clean.csv\", index_col= [0])\n",
    "df = df.reset_index(drop=True)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_dup_set(input_list):\n",
    "    result = []\n",
    "    for ele in input_list:\n",
    "        if ele not in result:\n",
    "            result.append(ele)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_df = df.corr()\n",
    "\n",
    "strong_neg_list = []\n",
    "weak_neg_list = []\n",
    "strong_pos_list = []\n",
    "weak_pos_list = []\n",
    "\n",
    "for col in corr_df.columns:\n",
    "    strong_neg = np.where(corr_df[col] < -0.7)\n",
    "    weak_neg = np.where((corr_df[col] >= -0.7) & (corr_df[col] < -0.4))\n",
    "    strong_pos = np.where((corr_df[col] > 0.7) & (corr_df[col] != 1))\n",
    "    weak_pos = np.where((corr_df[col] <= 0.7) & (corr_df[col] > 0.4))\n",
    "\n",
    "    strong_neg_list_temp = list(corr_df.index[strong_neg])\n",
    "    weak_neg_list_temp = list(corr_df.index[weak_neg])\n",
    "    strong_pos_list_temp = list(corr_df.index[strong_pos])\n",
    "    weak_pos_list_temp = list(corr_df.index[weak_pos])\n",
    "\n",
    "    strong_neg_list_temp = [{ele,col} for ele in strong_neg_list_temp]\n",
    "    weak_neg_list_temp = [ {ele,col} for ele in weak_neg_list_temp]\n",
    "    strong_pos_list_temp = [{ele,col} for ele in strong_pos_list_temp]\n",
    "    weak_pos_list_temp = [{ele,col} for ele in weak_pos_list_temp]\n",
    "\n",
    "    strong_neg_list = strong_neg_list + strong_neg_list_temp\n",
    "    weak_neg_list = weak_neg_list + weak_neg_list_temp\n",
    "    strong_pos_list = strong_pos_list + strong_pos_list_temp\n",
    "    weak_pos_list = weak_pos_list + weak_pos_list_temp\n",
    "\n",
    "strong_neg_list  = remove_dup_set(strong_neg_list)\n",
    "weak_neg_list = remove_dup_set(weak_neg_list)\n",
    "strong_pos_list = remove_dup_set(strong_pos_list)\n",
    "weak_pos_list = remove_dup_set(weak_pos_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's focus on the one that are hightly correlated\n",
    "\n",
    "# what can we observe from here\n",
    "sns.set(font_scale=1.7)\n",
    "fig, ax = plt.subplots(figsize=(20,20))  \n",
    "sns.heatmap(df.corr(), ax=ax, annot = True, vmin = 0.4, vmax = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "high 0.7 ~\n",
    "moderate 0.4 ~ 0.7\n",
    "weak ~0.4\n",
    "\n",
    "There are high correlation between weight and height\n",
    "moderate correlation between\n",
    "- weight & Doorling\n",
    "- height & Drooling\n",
    "- open to stranger & playfulness\n",
    "- energy level & playfulness\n",
    "- mental stimulation needs & playfullness\n",
    "- mental stimulation needs & energy level"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's focus on the one that are hightly correlated\n",
    "\n",
    "# what can we observe from here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what can we observe from here\n",
    "sns.set(font_scale=1.7)\n",
    "fig, ax = plt.subplots(figsize=(20,20))  \n",
    "sns.heatmap(df.corr(), ax=ax, annot = True, vmin = -1, vmax = -0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_factor = df.drop(['dog','color','marking','health','grooming','excercise','training','nutrition','Coat Type','Coat Length'],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_factor.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df_factor:\n",
    "    df_factor[col] = (df_factor[col] - df_factor[col].mean()) / df_factor[col].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_idx(df,dog_name):\n",
    "    return df[df['dog']== dog_name].index.to_list()[0]\n",
    "\n",
    "def get_names(df,dog_name):\n",
    "    dist_list = []\n",
    "    for i in range(df.shape[0]):\n",
    "        dist_list.append(np.linalg.norm(normalized_df_euclidean.iloc[get_idx(df,dog_name)]-normalized_df_euclidean.iloc[i]))\n",
    "    idx_list = sorted(range(len(dist_list)), key=lambda i: dist_list[i], reverse=False)[:6]\n",
    "    return df['dog'][idx_list], 1- (sorted(dist_list)[0:6] / sorted(dist_list)[-1])\n",
    "\n",
    "def euclidean_by_name(df, dog_name):\n",
    "    name_list, dis = get_names(df,dog_name)\n",
    "    for name,d in zip(name_list,dis):\n",
    "        print(name)\n",
    "        print(format(d,'.2%'), \"simliar to\", dog_name)\n",
    "        display(Image(filename=f'img/{name}.jpg'))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def similiar_dogs(df,idx):\n",
    "\n",
    "base = df_factor.loc[0]\n",
    "dist_list = []\n",
    "for i in range(df_factor.shape[0]):\n",
    "    dist_list.append(np.linalg.norm(base - df_factor.loc[i].values))\n",
    "df_factor['dist'] = dist_list\n",
    "df_factor = df_factor.sort_values(by = 'dist')\n",
    "df_factor.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Factor Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adequacy Test\n",
    "# Before you perform factor analysis, you need to evaluate the “factorability” of our dataset.\n",
    "# Factorability means \"can we found the factors in the dataset?\". There are two methods to check the factorability or sampling adequacy:\n",
    "from factor_analyzer.factor_analyzer import calculate_bartlett_sphericity\n",
    "chi_square_value,p_value=calculate_bartlett_sphericity(df_factor)\n",
    "chi_square_value, p_value\n",
    "\n",
    "from factor_analyzer.factor_analyzer import calculate_kmo\n",
    "kmo_all,kmo_model=calculate_kmo(df_factor)\n",
    "kmo_model\n",
    "\n",
    "# Create factor analysis object and perform factor analysis\n",
    "fa = FactorAnalyzer()\n",
    "fa.fit(df_factor)\n",
    "ev, v = fa.get_eigenvalues()\n",
    "\n",
    "plt.scatter(np.arange(1,len(ev)+1),ev)\n",
    "plt.plot(np.arange(1,len(ev)+1),ev)\n",
    "plt.title('Scree Plot')\n",
    "plt.xlabel('factors')\n",
    "plt.ylabel('eigenvalues of the factors')\n",
    "\n",
    "fa = FactorAnalyzer(4, rotation=\"varimax\")\n",
    "fa.fit(df_factor)\n",
    "fa.loadings_\n",
    "dir(fa)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,10))         # Sample figsize in inches\n",
    "sns.heatmap(fa.loadings_, annot = True, yticklabels= df_factor.columns, cmap=\"rocket_r\", ax = ax)\n",
    "\n",
    "# df_summary = pd.DataFrame(fa.get_factor_variance())\n",
    "# df_summary.columns = ['Factor1','Factor2','Factor3']\n",
    "# df_summary.index = ['SS Loadings', 'Proportion Var','Cumulative Var']\n",
    "\n",
    "# df_summary\n",
    "\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# cols = df.columns.drop(['DATE','ECOMM_SALES_AMT', 'RETAIL_SALES_AMT'])\n",
    "# # Separating out the features\n",
    "# x = df[cols].values\n",
    "# # Standardizing the features\n",
    "# x = StandardScaler().fit_transform(x)\n",
    "\n",
    "# from sklearn.decomposition import PCA\n",
    "# pca = PCA(n_components=2)\n",
    "# principalComponents = pca.fit_transform(x)\n",
    "# principalDf = pd.DataFrame(data = principalComponents\n",
    "#              , columns = ['principal component 1', 'principal component 2'])\n",
    "# ecomm_series = df[['ECOMM_SALES_AMT']].reset_index(drop=True)\n",
    "# finalDf = pd.concat([principalDf, ecomm_series], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "first Factor : height, weight, life, drooling (general ) \n",
    "second Factor : socail skill , perhaps, it indicate easy to train dog? This is a good indicator for popularity\n",
    "Third Factor : How energetic the dogs are (time to commit to dog)\n",
    "Last Facotr : watch dog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's think about the way to include hair and color into this picture\n",
    "\n",
    "Study more recommendation system"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "29f9ce33f6c884e3855952bfd7c8e1ec7ab3eef33d7abd85991a8524700c864f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
